{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a824943-6e50-4f88-bb3b-7d32f9ae0a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "DATA = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    categories=['rec.autos', 'comp.windows.x', 'soc.religion.christian', 'rec.sport.baseball']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e1b403-22aa-4237-ac2f-d80dd74fa112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.windows.x', 'rec.autos', 'rec.sport.baseball', 'soc.religion.christian']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e34672-fdb4-43a2-8a3f-9f1dd6d7ade4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe402fe5-8ae5-422f-99d2-721309b0801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = DATA.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb19c41-bdf3-4296-b2a0-2c5d01389765",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = [DATA.target_names[i] for i in DATA.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4c010c1-5f08-47b3-a44a-d53428012bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA : With all the recent problems the Indians have been having\n",
      "with their pitching staff I have heard numerous names\n",
      "thrown around about who could solve their problem.\n",
      "\n",
      "One name I have not heard is Mike Soper (RP).  As far as\n",
      "I know, Soper has had pretty good minor league stats.\n",
      "Why not give the kid a chance?  Anyone know anything about\n",
      "this guy?\n",
      "\n",
      "-- \n",
      "LABEL : rec.sport.baseball\n"
     ]
    }
   ],
   "source": [
    "print (f'DATA : {FEATURES[0]}')\n",
    "print (f'LABEL : {TARGET[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c70634-3e40-4d70-9ac4-94f3d396233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c24d1e3-5ff1-4572-9a7a-14c46ddac575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'soc.religion.christian': 398,\n",
       "         'rec.sport.baseball': 397,\n",
       "         'rec.autos': 396,\n",
       "         'comp.windows.x': 395})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "372cd0e5-a1a1-48e4-a51c-e3d19b2cea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e61304f5-bbf7-46ee-9375-9d934d3262b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(FEATURES , TARGET , test_size = .2 , stratify = TARGET,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c74864cb-737b-4652-93b8-40915ecc7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "vectorizer.fit(x_train)\n",
    "x_train_v = vectorizer.transform(x_train)\n",
    "x_test_v = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4532e43c-cba4-4353-afa7-bef08e85eabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nPlease note that God commanded Adam to work before the fall:\\n\\n\"The LORD God took the man and put him in the Garden of Eden to work\\n it and take care of it.\" (Gen 2:15, NIV).  \\n\\nWork was God\\'s design from the beginning.\\n\\n-- \\nKen'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85a8af76-d930-4047-b29b-fc3ab2c9d636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 18 stored elements and shape (1, 18556)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1caaa9f3-337c-4fd7-957b-9770d07aff5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a00b37be-8c08-4cc1-84c6-101802bf5477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nEither I've just fallen for this, or you guys\\nare _really_ paranoid!\\n\\nYou're actually worried about somebody stealing \\nyour oil?\\n\\nC'mon, you think a vandal'll do that?!\\n\\nThat's absolutely ridiculous!\\n\\nBesides, how hard is it to get under the car to \\nchange the oil?\\n\\nI can say from experience on the cars that I've driven and\\nchanged the oil on, my Mazda 323 is pretty much a pain, but\\nonce you've done it once, you don't forget how, and it\\ngets easier.\\n\\nI can't imagine any other cars are much worse than mine.\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56e316d2-0602-4c0c-bb3b-318fec127ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 32 stored elements and shape (1, 18556)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_v[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "987a750b-93c9-4777-afa1-7c3324d227cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.autos'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ff4b3ef-1d27-49ed-b267-3ada89d29213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 8\n",
      "true_label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.164\u001b[0m\n",
      "1 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.151\u001b[0m\n",
      "2 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.133\u001b[0m\n",
      "id: 126\n",
      "true_label: \u001b[32mrec.autos\u001b[0m\n",
      "0 nearest label is \u001b[32mrec.autos\u001b[0m, similarity: \u001b[33m0.218\u001b[0m\n",
      "1 nearest label is \u001b[32mrec.autos\u001b[0m, similarity: \u001b[33m0.216\u001b[0m\n",
      "2 nearest label is \u001b[32mrec.autos\u001b[0m, similarity: \u001b[33m0.214\u001b[0m\n",
      "id: 277\n",
      "true_label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.346\u001b[0m\n",
      "1 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.329\u001b[0m\n",
      "2 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.306\u001b[0m\n",
      "id: 312\n",
      "true_label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.216\u001b[0m\n",
      "1 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.204\u001b[0m\n",
      "2 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.195\u001b[0m\n",
      "id: 199\n",
      "true_label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.281\u001b[0m\n",
      "1 nearest label is \u001b[31mrec.sport.baseball\u001b[0m, similarity: \u001b[33m0.226\u001b[0m\n",
      "2 nearest label is \u001b[32msoc.religion.christian\u001b[0m, similarity: \u001b[33m0.221\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from termcolor import colored  # Ensure termcolor is installed: `pip install termcolor`\n",
    "\n",
    "for i in random.choices(range(len(x_test)), k=5):  # Randomly select 5 indices\n",
    "    print(f\"id: {i}\")\n",
    "    print(\"true_label:\", colored(y_test[i], 'green'))\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    distances = cosine_similarity(x_test_v[i].reshape(1, -1), x_train_v).flatten()\n",
    "\n",
    "    # Sort distances in descending order and get indices\n",
    "    indicies = np.argsort(distances)[::-1]\n",
    "\n",
    "    # Print the 3 nearest labels\n",
    "    for idx, j in enumerate(indicies[:3]):\n",
    "        print(\n",
    "            f\"{idx} nearest label is {colored(y_train[j], 'green' if y_train[j] == y_test[i] else 'red')}, \"\n",
    "            f\"similarity: {colored(round(distances[j], 3), 'yellow')}\"\n",
    "        )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
